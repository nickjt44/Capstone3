{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the data collection and cleaning section of the project. First, I import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import praw\n",
    "import requests\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from json import JSONDecodeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this project will be to search for relevant stock ticker symbols on r/wallstreetbets. I found a .csv file online which contains the majority of relevant stocks to search for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq = pd.read_csv('nasdaq_screener_1621717894156.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll quickly check the file, the ticker symbols are represented in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Last Sale</th>\n",
       "      <th>Net Change</th>\n",
       "      <th>% Change</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Country</th>\n",
       "      <th>IPO Year</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>Agilent Technologies Inc. Common Stock</td>\n",
       "      <td>$132.30</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.114%</td>\n",
       "      <td>4.031148e+10</td>\n",
       "      <td>United States</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1445930</td>\n",
       "      <td>Capital Goods</td>\n",
       "      <td>Electrical Products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>Alcoa Corporation Common Stock</td>\n",
       "      <td>$36.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.893%</td>\n",
       "      <td>6.748232e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>6897873</td>\n",
       "      <td>Basic Industries</td>\n",
       "      <td>Metal Fabrications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAC</th>\n",
       "      <td>Ares Acquisition Corporation Class A Ordinary ...</td>\n",
       "      <td>$9.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.102%</td>\n",
       "      <td>1.222500e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>391915</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Business Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACG</th>\n",
       "      <td>ATA Creativity Global American Depositary Shares</td>\n",
       "      <td>$2.93</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.384%</td>\n",
       "      <td>9.288448e+07</td>\n",
       "      <td>China</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314661</td>\n",
       "      <td>Miscellaneous</td>\n",
       "      <td>Service to the Health Industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AACQ</th>\n",
       "      <td>Artius Acquisition Inc. Class A Common Stock</td>\n",
       "      <td>$9.87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.101%</td>\n",
       "      <td>8.938519e+08</td>\n",
       "      <td>United States</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>867592</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Business Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Name Last Sale  \\\n",
       "Symbol                                                                \n",
       "A                  Agilent Technologies Inc. Common Stock   $132.30   \n",
       "AA                        Alcoa Corporation Common Stock     $36.14   \n",
       "AAC     Ares Acquisition Corporation Class A Ordinary ...     $9.78   \n",
       "AACG     ATA Creativity Global American Depositary Shares     $2.93   \n",
       "AACQ         Artius Acquisition Inc. Class A Common Stock     $9.87   \n",
       "\n",
       "        Net Change % Change    Market Cap        Country  IPO Year   Volume  \\\n",
       "Symbol                                                                        \n",
       "A             0.15   0.114%  4.031148e+10  United States    1999.0  1445930   \n",
       "AA            0.32   0.893%  6.748232e+09            NaN    2016.0  6897873   \n",
       "AAC           0.01   0.102%  1.222500e+09            NaN    2021.0   391915   \n",
       "AACG          0.04   1.384%  9.288448e+07          China       NaN   314661   \n",
       "AACQ          0.01   0.101%  8.938519e+08  United States    2020.0   867592   \n",
       "\n",
       "                  Sector                        Industry  \n",
       "Symbol                                                    \n",
       "A          Capital Goods             Electrical Products  \n",
       "AA      Basic Industries              Metal Fabrications  \n",
       "AAC              Finance               Business Services  \n",
       "AACG       Miscellaneous  Service to the Health Industry  \n",
       "AACQ             Finance               Business Services  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the stocks into a pandas series, and remove any ticker symbols which are too close to commonly used words. Most of the searches for these symbols will be primarily populated by irrelevant data, which will lead to misleading results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = pd.Series(nasdaq.index)\n",
    "\n",
    "stocks = stocks[~stocks.str.lower().isin(['a','be','by','bye','age','ago','buy','dd','yolo','to','and','end','fun','ad','ads','bot','ah','ahh','all','alt','am','etc',\n",
    "                        'an','apps','are','auto','bc','big','bill','bob','net','box','boom','bro','can','cap','care','cars','cat','cc','co','cold','cool',\n",
    "                        'core','cpa','cry','cs','cuz','bb','d','db','doc','door','earn','east','eat','echo','ego','em','eq','eric','es','et','eth','eva','ew',\n",
    "                        'eye','eyes','fam','fail','fast','farm','fat','fc','ff','flow','fold','for','form','free','fury','fuse','gl','go','gogo','good','h','ha','has','hall','hi',\n",
    "                        'hr','id','if','imo','ip','irl','it','itt','jack','jan','job','jobs','k','kids','l','lad','lazy','le','leg','life',\n",
    "                        'link','lite','ll','lmao','loop','love','m','man','min','mod','ms','nc','now','o','oc','ofc','one','or','pays','peak','phd','post',\n",
    "                        'rare','rave','road','safe','sa','save','see','ship','shop','sky','moon','so','solo','son','stay','hold','sum','t','ta','taco','tds',\n",
    "                         'tech','ten','tho','tv','tx','nc','sc','ty','u','v','vc','vs','w','wat','well','wish','wifi','work','x','y','z'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common words were missed in this step, and will need to be processed later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockslist = stocks.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function queries the Reddit Pushshift API. The size of each query is limited to 100, the query will return posts containing the query word/symbol between the specified times (Sep 1, 2020, and Feb 28, 2021)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_reddit_posts(query,start,end):\n",
    "    #print(query)\n",
    "    #query = query\n",
    "    #url = f\"https://api.pushshift.io/reddit/search/comment/?q={query}&subreddit=safemoon&size=500&after={start}&before={end}\"\n",
    "    \n",
    "    #url = f\"https://api.pushshift.io/reddit/search/submission/?subreddit=safemoon&size=500&after={start}&before={end}\"\n",
    "    url = f\"https://api.pushshift.io/reddit/search/submission/?q={query}&subreddit=wallstreetbets&size=100&after={start}&before={end}\"\n",
    "    request = requests.get(url)\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below makes successive calls to the function above, acquiring all Reddit posts pertaining to each stock symbol. Some try/except clauses are included so that the code can continue running in the event of an error, and just try to fetch the data again until successful.\n",
    "\n",
    "The code adds the author, post id, subreddit (which is always r/wallstreetbets), post content, post title, score, hyperlink location, timestamp, and the number of comments received by the post to a dataframe, for each post.\n",
    "\n",
    "The results for each stock symbol were saved to a separate .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.DataFrame(columns=[\"author\", \"id\", \"subreddit\", \"selftext\", \"num_comments\", \"score\", \"title\", \"permalink\",\"created_utc\"])\n",
    "\n",
    "start_epoch = 1598922001 #sep 1, 2020\n",
    "end_epoch = 1614556799 #feb 28, 2021\n",
    "\n",
    "epoch = start_epoch\n",
    "\n",
    "for i in range(len(stockslist)):\n",
    "    ticker = stockslist[i]\n",
    "    print(i)\n",
    "    print(ticker)\n",
    "    df_total = pd.DataFrame(columns=[\"author\", \"id\", \"subreddit\", \"selftext\", \"num_comments\", \"score\", \"title\", \"permalink\",\"link_flair_css_class\",\"created_utc\"])\n",
    "    epoch = start_epoch\n",
    "    while epoch < end_epoch:\n",
    "        try:\n",
    "            data = scrape_reddit_SFM(ticker,epoch, end_epoch)\n",
    "            print(len(data['data']))\n",
    "            if len(data['data']) == 0:\n",
    "                break\n",
    "            try:\n",
    "                epoch = data['data'][-1][\"created_utc\"] + 1\n",
    "            except:\n",
    "                print(\"error\")\n",
    "            print(epoch)\n",
    "            df = pd.DataFrame.from_records(data['data'])[[\"author\", \"id\", \"subreddit\", \"selftext\", \"num_comments\", \"score\", \"title\", \"permalink\",\"link_flair_css_class\",\"created_utc\"]]\n",
    "            df_total = df_total.append(df)\n",
    "            print(df_total.shape)\n",
    "            time.sleep(1)\n",
    "        except IndexError:\n",
    "            break\n",
    "            time.sleep(1)\n",
    "        except JSONDecodeError:\n",
    "            time.sleep(3)\n",
    "    df_total.to_csv('stockdfs/df_' + ticker + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I iterate over all the .csv files I saved in the previous steps, combining them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns=[\"author\", \"id\", \"subreddit\", \"selftext\", \"num_comments\", \"score\", \"title\", \"permalink\",\"link_flair_css_class\",\"created_utc\",\"stock\"])\n",
    "df_all = df_all.set_index('id')\n",
    "for filename in os.listdir('stockdfs/'):\n",
    "    print(filename)\n",
    "    df = pd.read_csv('stockdfs/' + filename,index_col=0)\n",
    "    df['stock'] = filename.split('_')[1].split('.')[0]\n",
    "    df = df.set_index('id')\n",
    "    for index, row in df.iterrows():\n",
    "        if df_all.index.isin([index]).any():\n",
    "            df_all.loc[index,'stock'] = df_all.loc[index,'stock'] + '|' + row[9]\n",
    "        else:\n",
    "            df_all = df_all.append(row)\n",
    "    #df_all = df_all.append(df)\n",
    "    print(df_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('df_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('df_all.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_reset = df_all.sort_values('created_utc').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I check whether there are any significant temporal gaps in the data which Pushshift may have missed, which I will need to fill in if so. I first calculate the time difference between each data point, and then plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n"
     ]
    }
   ],
   "source": [
    "for i,row in df_all_reset.iterrows():\n",
    "    if i == 0:\n",
    "        df_all_reset.loc[i,'timediff'] = 0\n",
    "    else:\n",
    "        df_all_reset.loc[i,'timediff'] = df_all_reset.loc[i,'created_utc'] - df_all_reset.loc[i-1,'created_utc']\n",
    "    if i%10000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x12832970250>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_all_reset.index,df_all_reset.timediff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot, and the table below, there are some significant outlying time gaps which need to be remedied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>stock</th>\n",
       "      <th>timediff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270161</th>\n",
       "      <td>leyfdu</td>\n",
       "      <td>endymionsleep</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>This post is not about GME</td>\n",
       "      <td>/r/wallstreetbets/comments/leyfdu/this_post_is...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.612740e+09</td>\n",
       "      <td>GME</td>\n",
       "      <td>261266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11227</th>\n",
       "      <td>jpa1ic</td>\n",
       "      <td>poache17</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>CVS!!!!!! who yolo'd onto that train with me?????</td>\n",
       "      <td>/r/wallstreetbets/comments/jpa1ic/cvs_who_yolo...</td>\n",
       "      <td>profit</td>\n",
       "      <td>1.604686e+09</td>\n",
       "      <td>CVS</td>\n",
       "      <td>146144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66445</th>\n",
       "      <td>l6649u</td>\n",
       "      <td>laiod</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>MARKET MANIPULATION BY SOME WALL STREET FUCKS....</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>SCHWAB SAYS $GME NOT VALID</td>\n",
       "      <td>/r/wallstreetbets/comments/l6649u/schwab_says_...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.611759e+09</td>\n",
       "      <td>GME</td>\n",
       "      <td>80866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>izhg70</td>\n",
       "      <td>___rash</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Appl and Tsla went up again</td>\n",
       "      <td>/r/wallstreetbets/comments/izhg70/appl_and_tsl...</td>\n",
       "      <td>stocks</td>\n",
       "      <td>1.601032e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>44478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270452</th>\n",
       "      <td>lfd807</td>\n",
       "      <td>judewilloughby</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RKT/TSLA</td>\n",
       "      <td>/r/wallstreetbets/comments/lfd807/rkttsla/</td>\n",
       "      <td>question</td>\n",
       "      <td>1.612795e+09</td>\n",
       "      <td>TSLA|RKT</td>\n",
       "      <td>39566.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>jemp04</td>\n",
       "      <td>aneebus</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>anyone on ACOR? up 140% pre market, what's goi...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ACOR</td>\n",
       "      <td>/r/wallstreetbets/comments/jemp04/acor/</td>\n",
       "      <td>question</td>\n",
       "      <td>1.603189e+09</td>\n",
       "      <td>ACOR</td>\n",
       "      <td>38013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>iv32ip</td>\n",
       "      <td>Aye_Barboza</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>TSLA +2.25% pre market. All aboard the spacesh...</td>\n",
       "      <td>/r/wallstreetbets/comments/iv32ip/tsla_225_pre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600422e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>35820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>k6cbx2</td>\n",
       "      <td>Jared2338</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Is their any point in talking about SPY calls ...</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>Does anyone talk about SPY anymore?</td>\n",
       "      <td>/r/wallstreetbets/comments/k6cbx2/does_anyone_...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.607051e+09</td>\n",
       "      <td>SPY</td>\n",
       "      <td>35811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>ixrzmn</td>\n",
       "      <td>DenkiAizen</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NKLA puts</td>\n",
       "      <td>/r/wallstreetbets/comments/ixrzmn/nkla_puts/</td>\n",
       "      <td>question</td>\n",
       "      <td>1.600796e+09</td>\n",
       "      <td>NKLA</td>\n",
       "      <td>34638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>jedula</td>\n",
       "      <td>wowscool</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Thoughts on NKLA?</td>\n",
       "      <td>/r/wallstreetbets/comments/jedula/thoughts_on_...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.603151e+09</td>\n",
       "      <td>NKLA</td>\n",
       "      <td>31395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293386</th>\n",
       "      <td>llzzbn</td>\n",
       "      <td>TradeIdeas2020</td>\n",
       "      <td>Wallstreetbetsnew</td>\n",
       "      <td>Sooner than than the HF's imagine!\\n\\n&amp;amp;#x2...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>NOBODY SELLING GME....IT IS GOING TO THE MOON!</td>\n",
       "      <td>/r/Wallstreetbetsnew/comments/llzzbn/nobody_se...</td>\n",
       "      <td>Chart</td>\n",
       "      <td>1.613584e+09</td>\n",
       "      <td>GME</td>\n",
       "      <td>28364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276497</th>\n",
       "      <td>lglbr3</td>\n",
       "      <td>DanielOldieLox</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>What's up with NLS</td>\n",
       "      <td>/r/wallstreetbets/comments/lglbr3/whats_up_wit...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.612929e+09</td>\n",
       "      <td>NLS</td>\n",
       "      <td>25897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293284</th>\n",
       "      <td>lln8v3</td>\n",
       "      <td>LL_2200</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>I’ve been seeing a lot of buzz on this and hon...</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Quick thoughts on Cathie’s PLTR purchase - sla...</td>\n",
       "      <td>/r/wallstreetbets/comments/lln8v3/quick_though...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.613541e+09</td>\n",
       "      <td>PLTR</td>\n",
       "      <td>25822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293085</th>\n",
       "      <td>llcru4</td>\n",
       "      <td>urakake</td>\n",
       "      <td>Wallstreetbetsnew</td>\n",
       "      <td>Hi I've really been enjoying watching the even...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Buying GME to hold forever</td>\n",
       "      <td>/r/Wallstreetbetsnew/comments/llcru4/buying_gm...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>1.613507e+09</td>\n",
       "      <td>GME</td>\n",
       "      <td>24510.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>j19awr</td>\n",
       "      <td>howdyadoolol</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>$AAPL to the moon confirmed $115 6/21 leaps</td>\n",
       "      <td>/r/wallstreetbets/comments/j19awr/aapl_to_the_...</td>\n",
       "      <td>dd</td>\n",
       "      <td>1.601288e+09</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>15908.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>j0o3t3</td>\n",
       "      <td>OneCardiologist1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Tesla’s everywhere. TSLA 500c 10/31 ?</td>\n",
       "      <td>/r/wallstreetbets/comments/j0o3t3/teslas_every...</td>\n",
       "      <td>dd</td>\n",
       "      <td>1.601198e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>15200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>iwc4bl</td>\n",
       "      <td>AllsFairInPlowinHoes</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>I know, I sound like an absolute cock knuckle....</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>Too late to get in on a Battery Day?</td>\n",
       "      <td>/r/wallstreetbets/comments/iwc4bl/too_late_to_...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.600601e+09</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>13862.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>jidk0d</td>\n",
       "      <td>SimoHayha360</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Fuck Winnie the Pooh.\\n\\nThis might be an ok t...</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>Heads up: Vagina might sanction Boeing, Raythe...</td>\n",
       "      <td>/r/wallstreetbets/comments/jidk0d/heads_up_vag...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.603715e+09</td>\n",
       "      <td>NIO</td>\n",
       "      <td>13247.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7158</th>\n",
       "      <td>j7akwo</td>\n",
       "      <td>Rojamo2914</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Hi team,\\nI can't seem to find the greeks on m...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Where are the greeks?</td>\n",
       "      <td>/r/wallstreetbets/comments/j7akwo/where_are_th...</td>\n",
       "      <td>options</td>\n",
       "      <td>1.602152e+09</td>\n",
       "      <td>SPY</td>\n",
       "      <td>11796.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>is0ntj</td>\n",
       "      <td>Aadi1511</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Point and Figure intraday trading strategies. ...</td>\n",
       "      <td>/r/wallstreetbets/comments/is0ntj/point_and_fi...</td>\n",
       "      <td>technicals</td>\n",
       "      <td>1.600012e+09</td>\n",
       "      <td>PNF</td>\n",
       "      <td>11654.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                author          subreddit  \\\n",
       "270161  leyfdu         endymionsleep     wallstreetbets   \n",
       "11227   jpa1ic              poache17     wallstreetbets   \n",
       "66445   l6649u                 laiod     wallstreetbets   \n",
       "5459    izhg70               ___rash     wallstreetbets   \n",
       "270452  lfd807        judewilloughby     wallstreetbets   \n",
       "9045    jemp04               aneebus     wallstreetbets   \n",
       "4082    iv32ip           Aye_Barboza     wallstreetbets   \n",
       "24344   k6cbx2             Jared2338     wallstreetbets   \n",
       "4787    ixrzmn            DenkiAizen     wallstreetbets   \n",
       "9044    jedula              wowscool     wallstreetbets   \n",
       "293386  llzzbn        TradeIdeas2020  Wallstreetbetsnew   \n",
       "276497  lglbr3        DanielOldieLox     wallstreetbets   \n",
       "293284  lln8v3               LL_2200     wallstreetbets   \n",
       "293085  llcru4               urakake  Wallstreetbetsnew   \n",
       "5721    j19awr          howdyadoolol     wallstreetbets   \n",
       "5665    j0o3t3      OneCardiologist1     wallstreetbets   \n",
       "4386    iwc4bl  AllsFairInPlowinHoes     wallstreetbets   \n",
       "9871    jidk0d          SimoHayha360     wallstreetbets   \n",
       "7158    j7akwo            Rojamo2914     wallstreetbets   \n",
       "3071    is0ntj              Aadi1511     wallstreetbets   \n",
       "\n",
       "                                                 selftext  num_comments  \\\n",
       "270161                                          [removed]             0   \n",
       "11227                                           [removed]             6   \n",
       "66445   MARKET MANIPULATION BY SOME WALL STREET FUCKS....            12   \n",
       "5459                                            [removed]             0   \n",
       "270452                                          [removed]             0   \n",
       "9045    anyone on ACOR? up 140% pre market, what's goi...             4   \n",
       "4082                                            [removed]             2   \n",
       "24344   Is their any point in talking about SPY calls ...            16   \n",
       "4787                                            [removed]             2   \n",
       "9044                                            [removed]             9   \n",
       "293386  Sooner than than the HF's imagine!\\n\\n&amp;#x2...            19   \n",
       "276497                                          [removed]             0   \n",
       "293284  I’ve been seeing a lot of buzz on this and hon...            29   \n",
       "293085  Hi I've really been enjoying watching the even...             7   \n",
       "5721                                                  NaN             2   \n",
       "5665                                                  NaN            12   \n",
       "4386    I know, I sound like an absolute cock knuckle....            79   \n",
       "9871    Fuck Winnie the Pooh.\\n\\nThis might be an ok t...            20   \n",
       "7158    Hi team,\\nI can't seem to find the greeks on m...            12   \n",
       "3071                                                  NaN             0   \n",
       "\n",
       "        score                                              title  \\\n",
       "270161      1                         This post is not about GME   \n",
       "11227       3  CVS!!!!!! who yolo'd onto that train with me?????   \n",
       "66445       1                         SCHWAB SAYS $GME NOT VALID   \n",
       "5459        1                        Appl and Tsla went up again   \n",
       "270452      1                                           RKT/TSLA   \n",
       "9045        1                                               ACOR   \n",
       "4082        1  TSLA +2.25% pre market. All aboard the spacesh...   \n",
       "24344       1                Does anyone talk about SPY anymore?   \n",
       "4787        1                                          NKLA puts   \n",
       "9044        0                                  Thoughts on NKLA?   \n",
       "293386      1     NOBODY SELLING GME....IT IS GOING TO THE MOON!   \n",
       "276497      1                                 What's up with NLS   \n",
       "293284      1  Quick thoughts on Cathie’s PLTR purchase - sla...   \n",
       "293085      1                         Buying GME to hold forever   \n",
       "5721        1        $AAPL to the moon confirmed $115 6/21 leaps   \n",
       "5665        1              Tesla’s everywhere. TSLA 500c 10/31 ?   \n",
       "4386        1               Too late to get in on a Battery Day?   \n",
       "9871        1  Heads up: Vagina might sanction Boeing, Raythe...   \n",
       "7158        1                              Where are the greeks?   \n",
       "3071        1  Point and Figure intraday trading strategies. ...   \n",
       "\n",
       "                                                permalink  \\\n",
       "270161  /r/wallstreetbets/comments/leyfdu/this_post_is...   \n",
       "11227   /r/wallstreetbets/comments/jpa1ic/cvs_who_yolo...   \n",
       "66445   /r/wallstreetbets/comments/l6649u/schwab_says_...   \n",
       "5459    /r/wallstreetbets/comments/izhg70/appl_and_tsl...   \n",
       "270452         /r/wallstreetbets/comments/lfd807/rkttsla/   \n",
       "9045              /r/wallstreetbets/comments/jemp04/acor/   \n",
       "4082    /r/wallstreetbets/comments/iv32ip/tsla_225_pre...   \n",
       "24344   /r/wallstreetbets/comments/k6cbx2/does_anyone_...   \n",
       "4787         /r/wallstreetbets/comments/ixrzmn/nkla_puts/   \n",
       "9044    /r/wallstreetbets/comments/jedula/thoughts_on_...   \n",
       "293386  /r/Wallstreetbetsnew/comments/llzzbn/nobody_se...   \n",
       "276497  /r/wallstreetbets/comments/lglbr3/whats_up_wit...   \n",
       "293284  /r/wallstreetbets/comments/lln8v3/quick_though...   \n",
       "293085  /r/Wallstreetbetsnew/comments/llcru4/buying_gm...   \n",
       "5721    /r/wallstreetbets/comments/j19awr/aapl_to_the_...   \n",
       "5665    /r/wallstreetbets/comments/j0o3t3/teslas_every...   \n",
       "4386    /r/wallstreetbets/comments/iwc4bl/too_late_to_...   \n",
       "9871    /r/wallstreetbets/comments/jidk0d/heads_up_vag...   \n",
       "7158    /r/wallstreetbets/comments/j7akwo/where_are_th...   \n",
       "3071    /r/wallstreetbets/comments/is0ntj/point_and_fi...   \n",
       "\n",
       "       link_flair_css_class   created_utc     stock  timediff  \n",
       "270161             question  1.612740e+09       GME  261266.0  \n",
       "11227                profit  1.604686e+09       CVS  146144.0  \n",
       "66445              question  1.611759e+09       GME   80866.0  \n",
       "5459                 stocks  1.601032e+09      TSLA   44478.0  \n",
       "270452             question  1.612795e+09  TSLA|RKT   39566.0  \n",
       "9045               question  1.603189e+09      ACOR   38013.0  \n",
       "4082                    NaN  1.600422e+09      TSLA   35820.0  \n",
       "24344              question  1.607051e+09       SPY   35811.0  \n",
       "4787               question  1.600796e+09      NKLA   34638.0  \n",
       "9044               question  1.603151e+09      NKLA   31395.0  \n",
       "293386                Chart  1.613584e+09       GME   28364.0  \n",
       "276497             question  1.612929e+09       NLS   25897.0  \n",
       "293284             question  1.613541e+09      PLTR   25822.0  \n",
       "293085           Discussion  1.613507e+09       GME   24510.0  \n",
       "5721                     dd  1.601288e+09      AAPL   15908.0  \n",
       "5665                     dd  1.601198e+09      TSLA   15200.0  \n",
       "4386                    NaN  1.600601e+09      TSLA   13862.0  \n",
       "9871               question  1.603715e+09       NIO   13247.0  \n",
       "7158                options  1.602152e+09       SPY   11796.0  \n",
       "3071             technicals  1.600012e+09       PNF   11654.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_reset.nlargest(20,'timediff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I construct a list of Reddit IDs with missing values between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_list = []\n",
    "for i,row in df_all_reset.nlargest(20,'timediff').iterrows():\n",
    "    missing_list.append((df_all_reset.loc[i-1,'id'],df_all_reset.loc[i,'id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lcsh9n', 'leyfdu'),\n",
       " ('jo9j4g', 'jpa1ic'),\n",
       " ('l5hig3', 'l6649u'),\n",
       " ('iz7kk5', 'izhg70'),\n",
       " ('lf36kb', 'lfd807'),\n",
       " ('jedula', 'jemp04'),\n",
       " ('iuv61d', 'iv32ip'),\n",
       " ('k615qo', 'k6cbx2'),\n",
       " ('ixj3kb', 'ixrzmn'),\n",
       " ('je3836', 'jedula'),\n",
       " ('llqu9p', 'llzzbn'),\n",
       " ('lgcxyo', 'lglbr3'),\n",
       " ('llfhdp', 'lln8v3'),\n",
       " ('ll3xzi', 'llcru4'),\n",
       " ('j16ghm', 'j19awr'),\n",
       " ('j0l4xv', 'j0o3t3'),\n",
       " ('iw9dkx', 'iwc4bl'),\n",
       " ('jib16b', 'jidk0d'),\n",
       " ('j78j61', 'j7akwo'),\n",
       " ('irxi5e', 'is0ntj')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Reddit PRAW library, and some functions for conversion to reddit ID values (which I did not write, they were available via searching the web for PRAW documentation), I scrape Reddit for the missing IDs, iterating through every ID between the IDs in the list, and storing ones from r/wallstreetbets. Unfortunately, there is no faster alternative I was aware of, and this was a very time-consuming process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='-',\n",
    "                     client_secret='-', password='-',\n",
    "                     user_agent='-', username='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base36encode(integer: int) -> str:\n",
    "    chars = '0123456789abcdefghijklmnopqrstuvwxyz'\n",
    "    sign = '-' if integer < 0 else ''\n",
    "    integer = abs(integer)\n",
    "    result = ''\n",
    "    while integer > 0:\n",
    "        integer, remainder = divmod(integer, 36)\n",
    "        result = chars[remainder] + result\n",
    "    return sign + result\n",
    "\n",
    "def base36decode(base36: str) -> int:\n",
    "    return int(base36, 36)\n",
    "\n",
    "def get_next_hundred_ids(start_id):\n",
    "    start_num = base36decode(start_id)\n",
    "    ids = []\n",
    "    id_num = -1\n",
    "    for id_num in range(start_num, start_num + 100):\n",
    "        ids.append(\"t3_\"+base36encode(id_num))\n",
    "    return ids, base36encode(id_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsb_new = pd.DataFrame(columns=[\"author\", \"id\", \"subreddit\", \"selftext\", \"num_comments\", \"score\", \"title\", \"permalink\",\"link_flair_css_class\",\"created_utc\"])\n",
    "\n",
    "for i in range(0,len(missing_list)):\n",
    "    start_id_str = missing_list[i][0]\n",
    "    end_id_str = missing_list[i][1]\n",
    "    print(start_id_str)\n",
    "    while True:\n",
    "        print(start_id_str)\n",
    "        ids, last_id_str = get_next_hundred_ids(start_id_str)\n",
    "        first_date = None\n",
    "        last_date = None\n",
    "        count_found = 0\n",
    "        if 't3_'+end_id_str in ids:\n",
    "            break\n",
    "        wsb = reddit.subreddit('wallstreetbets')\n",
    "        submissions = reddit.info(fullnames=ids)\n",
    "        for submission in submissions:\n",
    "            count_found += 1\n",
    "            submission_date = datetime.datetime.fromtimestamp(submission.created_utc)\n",
    "            if submission.subreddit == 'wallstreetbets' or submission.subreddit == 'Wallstreetbetsnew':\n",
    "                print(submission.id)\n",
    "                df_wsb_new = df_wsb_new.append({'author':submission.author,'id':submission.id,'subreddit':submission.subreddit,'selftext':submission.selftext,\n",
    "                                      'num_comments':submission.num_comments,'score':submission.score,'title':submission.title,'permalink':submission.permalink,\n",
    "                                      'link_flair_css_class':submission.link_flair_css_class,'created_utc':submission.created_utc},ignore_index=True)\n",
    "            if first_date is None:\n",
    "                first_date = submission_date\n",
    "            last_date = submission_date\n",
    "        start_id_str = base36encode(base36decode(last_id_str) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pushshift API's info on the number of comments, and the score values of the posts, is also not always accurate, so again I use the PRAW library to acquire more accurate data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsb_new = df_wsb_new.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsb_new.to_csv('wsb_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb = df_all.append(df_wsb_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,int(np.ceil((wsb.shape[0]/100)))):\n",
    "    firstindex = i*100\n",
    "    lastindex = (i+1)*100 - 1\n",
    "    ids = list(wsb.index[firstindex:lastindex])\n",
    "    ids = ['t3_' + idx for idx in ids]\n",
    "    print(i)\n",
    "    submissions = reddit.info(fullnames=ids)\n",
    "    #print(submissions)\n",
    "    for submission in submissions:\n",
    "        #print(submission.id)\n",
    "        wsb.loc[submission.id,'num_comments_true'] = submission.num_comments\n",
    "        wsb.loc[submission.id,'score_true'] = submission.score\n",
    "        wsb.loc[submission.id,'upvote_ratio'] = submission.upvote_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I acquire the comments for each Reddit submission. Reddit comments are in the form of trees, with the submission as the root, and each reply capable of branching off into more replies. This method of extracting comments was able to preserve this structure, recording the link id (the original post) and the parent id (the comment (or post) being replied to) for each comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "df_comments = pd.DataFrame(columns=[\"author\", \"id\",\"parent_id\", \"link_id\", \"subreddit\", \"body\", \"score\", \"permalink\", \"created_utc\"])\n",
    "for i,row in posts.iterrows():\n",
    "    count += 1\n",
    "    submission = reddit.submission(i)\n",
    "    \n",
    "    print('num comments:' + str(row['num_comments_true']))\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            submission.comments.replace_more(limit=None)\n",
    "            break\n",
    "        except Exception:\n",
    "            print(\"Handling replace_more exception\")\n",
    "            print(len(submission.comments.list()))\n",
    "    \n",
    "    for comment in submission.comments.list():\n",
    "\n",
    "        df_comments = df_comments.append({'author':comment.author,'id':comment.id,'parent_id':comment.parent_id,'link_id':comment.link_id,'subreddit':comment.subreddit,\n",
    "                           'body':comment.body,'score':comment.score,'permalink':comment.permalink,'created_utc':comment.created_utc},ignore_index=True)\n",
    "\n",
    "    print(count)\n",
    "    print(df_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsb.to_csv('aaa_posts.csv')\n",
    "df_comments.to_csv('aaa_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickj\\anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "posts = pd.read_csv('aaa_posts.csv',index_col=0)\n",
    "comments = pd.read_csv('aaa_comments.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I do some minor processing of the data before we move on to the next step.\n",
    "\n",
    "I remove any posts or comments where the author ID is inaccessible, which after the multiple methods used to get the data, took a few different forms.\n",
    "\n",
    "I also removed comments and posts authored by Reddit bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts[posts.author != '[deleted]']\n",
    "posts = posts[~posts.author.isna()]\n",
    "comments = comments[comments.author != '[deleted]']\n",
    "comments = comments[~comments.author.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334802, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>permalink</th>\n",
       "      <th>link_flair_css_class</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>stock</th>\n",
       "      <th>num_comments_true</th>\n",
       "      <th>score_true</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>il7w3w</th>\n",
       "      <td>merp206</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Alright retards so amc spiked up 15% on news t...</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>AMC puts</td>\n",
       "      <td>/r/wallstreetbets/comments/il7w3w/amc_puts/</td>\n",
       "      <td>options</td>\n",
       "      <td>1.599057e+09</td>\n",
       "      <td>AMC</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il81vu</th>\n",
       "      <td>JackMaverick7</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>$AMC up 15% today already and labor day weeken...</td>\n",
       "      <td>/r/wallstreetbets/comments/il81vu/amc_up_15_to...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.599058e+09</td>\n",
       "      <td>AMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>il848o</th>\n",
       "      <td>JackMaverick7</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>$AMC up 15% today already and big viewing numb...</td>\n",
       "      <td>/r/wallstreetbets/comments/il848o/amc_up_15_to...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.599058e+09</td>\n",
       "      <td>AMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilhn1t</th>\n",
       "      <td>Wiletj1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Good Expiration Date for Shorting AMC</td>\n",
       "      <td>/r/wallstreetbets/comments/ilhn1t/good_expirat...</td>\n",
       "      <td>question</td>\n",
       "      <td>1.599088e+09</td>\n",
       "      <td>AMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ili63n</th>\n",
       "      <td>Wiletj1</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>When Are Your AMC Puts Expiring</td>\n",
       "      <td>/r/wallstreetbets/comments/ili63n/when_are_you...</td>\n",
       "      <td>shitpost</td>\n",
       "      <td>1.599089e+09</td>\n",
       "      <td>AMC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author       subreddit  \\\n",
       "id                                      \n",
       "il7w3w        merp206  wallstreetbets   \n",
       "il81vu  JackMaverick7  wallstreetbets   \n",
       "il848o  JackMaverick7  wallstreetbets   \n",
       "ilhn1t        Wiletj1  wallstreetbets   \n",
       "ili63n        Wiletj1  wallstreetbets   \n",
       "\n",
       "                                                 selftext  num_comments  \\\n",
       "id                                                                        \n",
       "il7w3w  Alright retards so amc spiked up 15% on news t...            19   \n",
       "il81vu                                                NaN             2   \n",
       "il848o                                                NaN             2   \n",
       "ilhn1t                                          [removed]             2   \n",
       "ili63n                                          [removed]             2   \n",
       "\n",
       "        score                                              title  \\\n",
       "id                                                                 \n",
       "il7w3w      1                                           AMC puts   \n",
       "il81vu      1  $AMC up 15% today already and labor day weeken...   \n",
       "il848o      1  $AMC up 15% today already and big viewing numb...   \n",
       "ilhn1t      1              Good Expiration Date for Shorting AMC   \n",
       "ili63n      1                    When Are Your AMC Puts Expiring   \n",
       "\n",
       "                                                permalink  \\\n",
       "id                                                          \n",
       "il7w3w        /r/wallstreetbets/comments/il7w3w/amc_puts/   \n",
       "il81vu  /r/wallstreetbets/comments/il81vu/amc_up_15_to...   \n",
       "il848o  /r/wallstreetbets/comments/il848o/amc_up_15_to...   \n",
       "ilhn1t  /r/wallstreetbets/comments/ilhn1t/good_expirat...   \n",
       "ili63n  /r/wallstreetbets/comments/ili63n/when_are_you...   \n",
       "\n",
       "       link_flair_css_class   created_utc stock  num_comments_true  \\\n",
       "id                                                                   \n",
       "il7w3w              options  1.599057e+09   AMC               22.0   \n",
       "il81vu             question  1.599058e+09   AMC                1.0   \n",
       "il848o             question  1.599058e+09   AMC                1.0   \n",
       "ilhn1t             question  1.599088e+09   AMC                1.0   \n",
       "ili63n             shitpost  1.599089e+09   AMC                1.0   \n",
       "\n",
       "        score_true  upvote_ratio  \n",
       "id                                \n",
       "il7w3w         9.0          0.81  \n",
       "il81vu         1.0          1.00  \n",
       "il848o         1.0          1.00  \n",
       "ilhn1t         1.0          1.00  \n",
       "ili63n         1.0          1.00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2534510, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>permalink</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MnVikingsFan34</td>\n",
       "      <td>g3jg6ae</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>About as likely as me regaining my missing chr...</td>\n",
       "      <td>69</td>\n",
       "      <td>/r/wallstreetbets/comments/ikazok/what_are_the...</td>\n",
       "      <td>1.598924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hedgeAgainst</td>\n",
       "      <td>g3jgdna</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Not happening. AMZN is the new BRK.A.</td>\n",
       "      <td>93</td>\n",
       "      <td>/r/wallstreetbets/comments/ikazok/what_are_the...</td>\n",
       "      <td>1.598924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252610</th>\n",
       "      <td>RainMan214</td>\n",
       "      <td>g3jgg4f</td>\n",
       "      <td>ikb0s0</td>\n",
       "      <td>ikb0s0</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Holy shit</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/wallstreetbets/comments/ikb0s0/did_i_win_39...</td>\n",
       "      <td>1.598924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hedgeAgainst</td>\n",
       "      <td>g3jgho0</td>\n",
       "      <td>g3jg6ae</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Musk will reveal his new gene therapy next month.</td>\n",
       "      <td>2</td>\n",
       "      <td>/r/wallstreetbets/comments/ikazok/what_are_the...</td>\n",
       "      <td>1.598924e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RainMan214</td>\n",
       "      <td>g3jgjio</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>ikazok</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>Why not wait till he announces the split? If i...</td>\n",
       "      <td>1</td>\n",
       "      <td>/r/wallstreetbets/comments/ikazok/what_are_the...</td>\n",
       "      <td>1.598924e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author       id parent_id link_id       subreddit  \\\n",
       "1       MnVikingsFan34  g3jg6ae    ikazok  ikazok  wallstreetbets   \n",
       "0         hedgeAgainst  g3jgdna    ikazok  ikazok  wallstreetbets   \n",
       "252610      RainMan214  g3jgg4f    ikb0s0  ikb0s0  wallstreetbets   \n",
       "30        hedgeAgainst  g3jgho0   g3jg6ae  ikazok  wallstreetbets   \n",
       "21          RainMan214  g3jgjio    ikazok  ikazok  wallstreetbets   \n",
       "\n",
       "                                                     body  score  \\\n",
       "1       About as likely as me regaining my missing chr...     69   \n",
       "0                   Not happening. AMZN is the new BRK.A.     93   \n",
       "252610                                          Holy shit      2   \n",
       "30      Musk will reveal his new gene therapy next month.      2   \n",
       "21      Why not wait till he announces the split? If i...      1   \n",
       "\n",
       "                                                permalink   created_utc  \n",
       "1       /r/wallstreetbets/comments/ikazok/what_are_the...  1.598924e+09  \n",
       "0       /r/wallstreetbets/comments/ikazok/what_are_the...  1.598924e+09  \n",
       "252610  /r/wallstreetbets/comments/ikb0s0/did_i_win_39...  1.598924e+09  \n",
       "30      /r/wallstreetbets/comments/ikazok/what_are_the...  1.598924e+09  \n",
       "21      /r/wallstreetbets/comments/ikazok/what_are_the...  1.598924e+09  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemindMeBot          2194\n",
       "WSBVoteBot           2107\n",
       "OverpricedBagel      1832\n",
       "pickbot              1712\n",
       "Unlucky-Prize        1704\n",
       "                     ... \n",
       "FraydoeDeLaTierra       1\n",
       "itumii                  1\n",
       "poet1620                1\n",
       "Captain_Canuck71        1\n",
       "BigEv17                 1\n",
       "Name: author, Length: 450695, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments[~comments.author.isin(['RemindMeBot','WSBVoteBot','pickbot'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OverpricedBagel       1832\n",
       "Unlucky-Prize         1704\n",
       "Dan_inKuwait          1463\n",
       "Trueslyforaniceguy    1330\n",
       "Ackilles              1181\n",
       "                      ... \n",
       "librarn1989              1\n",
       "FraydoeDeLaTierra        1\n",
       "itumii                   1\n",
       "poet1620                 1\n",
       "BigEv17                  1\n",
       "Name: author, Length: 450692, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#NAME?                  164\n",
       "Onboarding92            140\n",
       "phan1129                123\n",
       "True-Law7645             77\n",
       "kokoloko1010             75\n",
       "                       ... \n",
       "iGOmoon                   1\n",
       "RealLibertyMatters        1\n",
       "Kooky-Piccolo1207         1\n",
       "Intelligent-Tooth-44      1\n",
       "noahni74                  1\n",
       "Name: author, Length: 210126, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = posts[posts.author != '#NAME?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Onboarding92            140\n",
       "phan1129                123\n",
       "True-Law7645             77\n",
       "kokoloko1010             75\n",
       "mkaykov                  69\n",
       "                       ... \n",
       "RealLibertyMatters        1\n",
       "Kooky-Piccolo1207         1\n",
       "Intelligent-Tooth-44      1\n",
       "Legitimate-Bite-1180      1\n",
       "noahni74                  1\n",
       "Name: author, Length: 210125, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = comments[comments.link_id.isin(posts.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2526827, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, I save the posts and comments to .csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.to_csv('posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('comments.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
